{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "# import library yang dibutuhkan\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import zipfile,os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from rembg.bg import remove\n",
    "import easygui\n",
    "from PIL import Image\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import wget\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direktori sudah ada isinya\n"
     ]
    }
   ],
   "source": [
    "# check directory\n",
    "if os.path.exists('./train'):\n",
    "    print('Direktori sudah ada isinya')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from rembg import remove\n",
    "# from PIL import Image\n",
    "\n",
    "# def remove_background(input_path, output_path):\n",
    "#     try:\n",
    "#         input_image = Image.open(input_path) # ngebuka filenya\n",
    "#         output_image = remove(input_image) # ngehapus background -> library rembg\n",
    "#         output_image.save(output_path) # nyimpen yang udah diapus ke background\n",
    "#     except Exception as e: # kalo gagal nyimpen yg removed background disimpen di log\n",
    "#         with open(\"error_log.txt\", \"a\") as log_file:\n",
    "#             log_file.write(f\"Error processing {input_path}: {e}\\n\")\n",
    "\n",
    "# def remove_background_serial(input_dir, output_dir):  # loop remove semua\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "\n",
    "#     for filename in os.listdir(input_dir):\n",
    "#         input_path = os.path.join(input_dir, filename)\n",
    "#         output_path = os.path.join(output_dir, filename) # masukkin gambarnya\n",
    "#         remove_background(input_path, output_path)\n",
    "\n",
    "# # Use serial processing for background removal\n",
    "# original_dataset_dir = './train'  # Replace with your dataset directory\n",
    "# processed_dataset_dir = './processed'\n",
    "# categories = ['fall', 'non_fall']\n",
    "\n",
    "# subjects = [f for f in os.listdir('./train') if os.path.isdir(os.path.join('./train', f))]\n",
    "\n",
    "# for subject in subjects:\n",
    "#     for category in categories:\n",
    "#         input_dir = os.path.join('./train', subject, category) # file train\n",
    "#         output_dir = os.path.join('./processed', subject, category) # file buat nyimpen hasil\n",
    "\n",
    "#         if os.path.exists(input_dir):\n",
    "#             remove_background_serial(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from rembg import remove\n",
    "from PIL import Image\n",
    "\n",
    "def remove_background(input_path, output_path):\n",
    "    try:\n",
    "        input_image = Image.open(input_path) # ngebuka filenya\n",
    "        output_image = remove(input_image) # ngehapus background -> library rembg\n",
    "        output_image.save(output_path) # nyimpen yang udah diapus ke background\n",
    "    except Exception as e: # kalo gagal nyimpen yg removed background disimpen di log\n",
    "        with open(\"error_log.txt\", \"a\") as log_file:\n",
    "            log_file.write(f\"Error processing {input_path}: {e}\\n\")\n",
    "\n",
    "# serial processing for background removal\n",
    "def remove_background_serial(input_dir, output_dir): # loop remove background semua\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        output_path = os.path.join(output_dir, filename) # masukkin gambarnya\n",
    "        remove_background(input_path, output_path)\n",
    "\n",
    "# path dataset asli dan hasil\n",
    "original_dataset_dir = './train'  # file train (dataset asli)\n",
    "processed_dataset_dir = './processed'  # file buat nyimpen hasil\n",
    "categories = ['fall', 'non_fall']\n",
    "\n",
    "# penghapusan background untuk setiap kategori dalam setiap subdirektori (subject)\n",
    "subjects = [f for f in os.listdir(original_dataset_dir) if os.path.isdir(os.path.join(original_dataset_dir, f))]\n",
    "\n",
    "for subject in subjects:\n",
    "    for category in categories:\n",
    "        input_dir = os.path.join(original_dataset_dir, subject, category)\n",
    "        output_dir = os.path.join(processed_dataset_dir, subject, category)\n",
    "\n",
    "        if os.path.exists(input_dir):\n",
    "            remove_background_serial(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # membuat direktori untuk data training dan data validasi\n",
    "# base_dir = './processed'\n",
    "# train_dir = os.path.join(base_dir, 'train')\n",
    "# validation_dir = os.path.join(base_dir, 'val')\n",
    "\n",
    "# # membuat direktori untuk data training \n",
    "# train_fall_dir = os.path.join(train_dir, 'fall') \n",
    "# train_non_fall_dir = os.path.join(train_dir, 'non_fall')\n",
    "\n",
    "# # membuat direktori untuk data validasi\n",
    "# validation_fall_dir = os.path.join(validation_dir, 'fall')\n",
    "# validation_non_fall_dir = os.path.join(validation_dir, 'non_fall')\n",
    "\n",
    "# # membuat direktori untuk data training dan data validasi\n",
    "# if not os.path.exists(train_dir):\n",
    "#     os.mkdir(train_dir)\n",
    "# if not os.path.exists(validation_dir):\n",
    "#     os.mkdir(validation_dir)\n",
    "\n",
    "# if not os.path.exists(train_fall_dir):\n",
    "#     os.mkdir(train_fall_dir)\n",
    "# if not os.path.exists(train_non_fall_dir):\n",
    "#     os.mkdir(train_non_fall_dir)\n",
    "\n",
    "# if not os.path.exists(validation_fall_dir):\n",
    "#     os.mkdir(validation_fall_dir)\n",
    "# if not os.path.exists(validation_non_fall_dir):\n",
    "#     os.mkdir(validation_non_fall_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check kosong\n",
      "check kosong\n",
      "check kosong\n",
      "check kosong\n",
      "check kosong\n",
      "check kosong\n",
      "check kosong\n",
      "check kosong\n"
     ]
    }
   ],
   "source": [
    "# membuat direktori data training dan validasi\n",
    "base_dir = './processed_split'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'val')\n",
    "\n",
    "# membuat subdirektori untuk kategori (data training)\n",
    "train_fall_dir = os.path.join(train_dir, 'fall')\n",
    "train_non_fall_dir = os.path.join(train_dir, 'non_fall')\n",
    "\n",
    "# membuat subdirektori untuk kategori (data validasi)\n",
    "validation_fall_dir = os.path.join(validation_dir, 'fall')\n",
    "validation_non_fall_dir = os.path.join(validation_dir, 'non_fall')\n",
    "\n",
    "# membuat semua direktori jika belum ada\n",
    "for directory in [train_dir, validation_dir, train_fall_dir, train_non_fall_dir, validation_fall_dir, validation_non_fall_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# membagi dataset ke dalam train dan validation\n",
    "train_fall = []\n",
    "validation_fall = []\n",
    "train_non_fall = []\n",
    "validation_non_fall = []\n",
    "\n",
    "for subject in subjects:\n",
    "    # fall\n",
    "    fall_dir = os.path.join(processed_dataset_dir, subject, 'fall')\n",
    "    fall_images = os.listdir(fall_dir) if os.path.exists(fall_dir) else []\n",
    "    \n",
    "    if len(fall_images) > 0:  # cek apakah direktori tidak kosong\n",
    "        train, val = train_test_split(fall_images, test_size=0.4, random_state=None)\n",
    "        train_fall += [(subject, 'fall', img) for img in train]\n",
    "        validation_fall += [(subject, 'fall', img) for img in val]\n",
    "    else:\n",
    "        print(\"check kosong\")\n",
    "\n",
    "    # non-fall\n",
    "    non_fall_dir = os.path.join(processed_dataset_dir, subject, 'non_fall')\n",
    "    non_fall_images = os.listdir(non_fall_dir) if os.path.exists(non_fall_dir) else []\n",
    "    \n",
    "    if len(non_fall_images) > 0:  # cek apakah direktori tidak kosong\n",
    "        train, val = train_test_split(non_fall_images, test_size=0.4, random_state=None)\n",
    "        train_non_fall += [(subject, 'non_fall', img) for img in train]\n",
    "        validation_non_fall += [(subject, 'non_fall', img) for img in val]\n",
    "    else:\n",
    "        print(\"check kosong\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membagi data train dan data validation dengan perbandingan 60:40 \n",
    "\n",
    "subjects = [f for f in os.listdir('./processed') if os.path.isdir(os.path.join('./processed', f))]\n",
    "train_fall = []\n",
    "validation_fall = []\n",
    "\n",
    "for subject in subjects:\n",
    "    fall_images = os.listdir(os.path.join('./processed', subject, 'fall'))\n",
    "    train, val = train_test_split(fall_images, test_size=0.4, random_state=None)\n",
    "    train_fall += [os.path.join(subject, 'fall', img) for img in train]\n",
    "    validation_fall += [os.path.join(subject, 'fall', img) for img in val]\n",
    "\n",
    "# train test split jika direktori belum ada isinya\n",
    "if len(os.listdir('./train/fall')) == 0 and len(os.listdir('./train/non_fall')) == 0 :\n",
    "    # fall\n",
    "    train_fall = os.listdir('./processed/fall')\n",
    "    validation_fall = os.listdir('./processed/fall')\n",
    "    train_fall, validation_fall = train_test_split(train_fall, test_size = 0.4, random_state=None)\n",
    "\n",
    "    # non_fall\n",
    "    train_non_fall = os.listdir('./processed/non_fall')\n",
    "    validation_non_fall = os.listdir('./processed/non_fall')\n",
    "    train_non_fall, validation_non_fall = train_test_split(train_non_fall, test_size = 0.4, random_state=None)\n",
    "\n",
    "    # Memindahkan file gambar ke direktori data training (train)\n",
    "    for image in train_fall:\n",
    "        shutil.move(os.path.join('./processed/fall', image), os.path.join(train_fall_dir, image))\n",
    "    for image in train_non_fall:\n",
    "        shutil.move(os.path.join('./processed/non_fall', image), os.path.join(train_non_fall_dir, image))\n",
    "\n",
    "    # Memindahkan file gambar ke direktori data validasi (validation)\n",
    "    for image in validation_fall:\n",
    "        shutil.move(os.path.join('./processed/fall', image), os.path.join(validation_fall_dir, image))\n",
    "    for image in validation_non_fall:\n",
    "        shutil.move(os.path.join('./processed/non_fall', image), os.path.join(validation_non_fall_dir, image))\n",
    "else:\n",
    "    print('Direktori sudah ada isinya')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset berhasil diproses dan dipisahkan ke dalam direktori training dan validasi.\n"
     ]
    }
   ],
   "source": [
    "# memindahkan file ke direktori training dan validasi\n",
    "for subject, category, image in train_fall:\n",
    "    src = os.path.join(processed_dataset_dir, subject, category, image)\n",
    "    dst = os.path.join(train_fall_dir, image)\n",
    "    shutil.move(src, dst)\n",
    "\n",
    "for subject, category, image in validation_fall:\n",
    "    src = os.path.join(processed_dataset_dir, subject, category, image)\n",
    "    dst = os.path.join(validation_fall_dir, image)\n",
    "    shutil.move(src, dst)\n",
    "\n",
    "for subject, category, image in train_non_fall:\n",
    "    src = os.path.join(processed_dataset_dir, subject, category, image)\n",
    "    dst = os.path.join(train_non_fall_dir, image)\n",
    "    shutil.move(src, dst)\n",
    "\n",
    "for subject, category, image in validation_non_fall:\n",
    "    src = os.path.join(processed_dataset_dir, subject, category, image)\n",
    "    dst = os.path.join(validation_non_fall_dir, image)\n",
    "    shutil.move(src, dst)\n",
    "\n",
    "print(\"Dataset berhasil diproses dan dipisahkan ke dalam direktori training dan validasi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membagi data train dan data validation dengan perbandingan 60:40\n",
    "\n",
    "# Train test split jika direktori belum ada isinya\n",
    "if all(len(os.listdir(os.path.join('./processed_split/train', category))) == 0 for category in ['fall', 'non_fall']):\n",
    "    train_fall = []\n",
    "    validation_fall = []\n",
    "    train_non_fall = []\n",
    "    validation_non_fall = []\n",
    "\n",
    "    # Iterasi untuk setiap subject\n",
    "    for subject in subjects:\n",
    "        # Fall\n",
    "        fall_dir = os.path.join(processed_dataset_dir, subject, 'fall')\n",
    "        fall_images = os.listdir(fall_dir) if os.path.exists(fall_dir) else []\n",
    "\n",
    "        if len(fall_images) > 0:  # Cek apakah direktori tidak kosong\n",
    "            train, val = train_test_split(fall_images, test_size=0.4, random_state=None)\n",
    "            train_fall += [(subject, 'fall', img) for img in train]\n",
    "            validation_fall += [(subject, 'fall', img) for img in val]\n",
    "\n",
    "        # Non-fall\n",
    "        non_fall_dir = os.path.join(processed_dataset_dir, subject, 'non_fall')\n",
    "        non_fall_images = os.listdir(non_fall_dir) if os.path.exists(non_fall_dir) else []\n",
    "\n",
    "        if len(non_fall_images) > 0:  # Cek apakah direktori tidak kosong\n",
    "            train, val = train_test_split(non_fall_images, test_size=0.4, random_state=None)\n",
    "            train_non_fall += [(subject, 'non_fall', img) for img in train]\n",
    "            validation_non_fall += [(subject, 'non_fall', img) for img in val]\n",
    "\n",
    "    # Memindahkan file gambar ke direktori data training (train)\n",
    "    for subject, category, image in train_fall:\n",
    "        src = os.path.join(processed_dataset_dir, subject, category, image)\n",
    "        dst = os.path.join(train_fall_dir, image)\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "    for subject, category, image in train_non_fall:\n",
    "        src = os.path.join(processed_dataset_dir, subject, category, image)\n",
    "        dst = os.path.join(train_non_fall_dir, image)\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "    # Memindahkan file gambar ke direktori data validasi (validation)\n",
    "    for subject, category, image in validation_fall:\n",
    "        src = os.path.join(processed_dataset_dir, subject, category, image)\n",
    "        dst = os.path.join(validation_fall_dir, image)\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "    for subject, category, image in validation_non_fall:\n",
    "        src = os.path.join(processed_dataset_dir, subject, category, image)\n",
    "        dst = os.path.join(validation_non_fall_dir, image)\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "else:\n",
    "    print('Direktori sudah ada isinya')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non_fall', 'fall']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# menampilkan nama kelas yang ada pada train\n",
    "os.listdir('./processed/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non_fall', 'fall']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# menampilkan nama kelas yang ada pada train\n",
    "os.listdir('./processed/val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rembg import remove\n",
    "from PIL import Image\n",
    "\n",
    "# 1. Fungsi Preprocessing Gambar\n",
    "def preprocess_img(img):\n",
    "    img = cv2.GaussianBlur(img, (5, 5), 0)  # Menghaluskan gambar\n",
    "    img = tf.image.adjust_contrast(img, 2)  # Menyesuaikan kontras gambar\n",
    "    return img\n",
    "\n",
    "# 2. Fungsi Penghapusan Background\n",
    "def remove_background(input_path, output_path):\n",
    "    try:\n",
    "        input_image = Image.open(input_path)\n",
    "        output_image = remove(input_image)\n",
    "        output_image.save(output_path)\n",
    "    except Exception as e:\n",
    "        with open(\"error_log.txt\", \"a\") as log_file:\n",
    "            log_file.write(f\"Error processing {input_path}: {e}\\n\")\n",
    "\n",
    "def remove_background_serial(input_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        remove_background(input_path, output_path)\n",
    "\n",
    "# 3. Path Dataset\n",
    "original_dataset_dir = './train'\n",
    "processed_dataset_dir = './processed'\n",
    "categories = ['fall', 'non_fall']\n",
    "\n",
    "# Memproses dataset untuk setiap subjek dan kategori\n",
    "subjects = [f for f in os.listdir(original_dataset_dir) if os.path.isdir(os.path.join(original_dataset_dir, f))]\n",
    "for subject in subjects:\n",
    "    for category in categories:\n",
    "        input_dir = os.path.join(original_dataset_dir, subject, category)\n",
    "        output_dir = os.path.join(processed_dataset_dir, subject, category)\n",
    "        if os.path.exists(input_dir):\n",
    "            remove_background_serial(input_dir, output_dir)\n",
    "\n",
    "# 4. Membagi Data Train dan Validation\n",
    "base_dir = './processed_split'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'val')\n",
    "train_fall_dir = os.path.join(train_dir, 'fall')\n",
    "train_non_fall_dir = os.path.join(train_dir, 'non_fall')\n",
    "validation_fall_dir = os.path.join(validation_dir, 'fall')\n",
    "validation_non_fall_dir = os.path.join(validation_dir, 'non_fall')\n",
    "\n",
    "for directory in [train_dir, validation_dir, train_fall_dir, train_non_fall_dir, validation_fall_dir, validation_non_fall_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "train_fall = []\n",
    "validation_fall = []\n",
    "train_non_fall = []\n",
    "validation_non_fall = []\n",
    "\n",
    "for subject in subjects:\n",
    "    fall_dir = os.path.join(processed_dataset_dir, subject, 'fall')\n",
    "    fall_images = os.listdir(fall_dir) if os.path.exists(fall_dir) else []\n",
    "    if len(fall_images) > 0:\n",
    "        train, val = train_test_split(fall_images, test_size=0.4, random_state=None)\n",
    "        train_fall += [(subject, 'fall', img) for img in train]\n",
    "        validation_fall += [(subject, 'fall', img) for img in val]\n",
    "\n",
    "    non_fall_dir = os.path.join(processed_dataset_dir, subject, 'non_fall')\n",
    "    non_fall_images = os.listdir(non_fall_dir) if os.path.exists(non_fall_dir) else []\n",
    "    if len(non_fall_images) > 0:\n",
    "        train, val = train_test_split(non_fall_images, test_size=0.4, random_state=None)\n",
    "        train_non_fall += [(subject, 'non_fall', img) for img in train]\n",
    "        validation_non_fall += [(subject, 'non_fall', img) for img in val]\n",
    "\n",
    "for subject, category, image in train_fall:\n",
    "    src = os.path.join(processed_dataset_dir, subject, category, image)\n",
    "    dst = os.path.join(train_fall_dir, image)\n",
    "    shutil.move(src, dst)\n",
    "\n",
    "for subject, category, image in validation_fall:\n",
    "    src = os.path.join(processed_dataset_dir, subject, category, image)\n",
    "    dst = os.path.join(validation_fall_dir, image)\n",
    "    shutil.move(src, dst)\n",
    "\n",
    "for subject, category, image in train_non_fall:\n",
    "    src = os.path.join(processed_dataset_dir, subject, category, image)\n",
    "    dst = os.path.join(train_non_fall_dir, image)\n",
    "    shutil.move(src, dst)\n",
    "\n",
    "for subject, category, image in validation_non_fall:\n",
    "    src = os.path.join(processed_dataset_dir, subject, category, image)\n",
    "    dst = os.path.join(validation_non_fall_dir, image)\n",
    "    shutil.move(src, dst)\n",
    "\n",
    "# 5. ImageDataGenerator untuk Training dan Validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    shear_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    preprocessing_function=preprocess_img,\n",
    "    brightness_range=[0.5, 1.5],\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 6. Load dan Augmentasi Gambar untuk Visualisasi\n",
    "img_path = './processed_split/train/fall/example_image.jpg'  # Ganti dengan path gambar yang tersedia\n",
    "img = tf.keras.preprocessing.image.load_img(img_path)\n",
    "x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.suptitle('Augmented Images')\n",
    "\n",
    "i = 0\n",
    "for batch in train_datagen.flow(x, batch_size=1):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i >= 6:\n",
    "        break\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Proses selesai. Dataset telah diproses dan dibagi menjadi train dan validation.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
